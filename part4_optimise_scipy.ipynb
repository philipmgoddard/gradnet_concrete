{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 3: Optimising mixtures\n",
    "\n",
    "Our aim was to be able to predict mixtures that would lead to optimal compressive strengths to guide experminentation. We now have a model that can predict compressive strength based on mixture proportions, and the final step is to use an optimiser to find the mixture that produces the strongest concrete.\n",
    "\n",
    "We will use the [Scipy library](https://www.scipy.org/), which contains an optimiser for this purpose. We firstly have to define a cost function which we want to minimise, and then we will run the optmiser from different starting points to find our candidate mixtures. Using different starting points is important, as we have no guarentee to find the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data and both our models. We will focus on the GBR model, as it\n",
    "# is faster to make predictions.\n",
    "# You can investigate the RF model as well in your own time\n",
    "\n",
    "test = pd.read_csv(\"processed/test_proportion.csv\")\n",
    "\n",
    "with open(\"/home/phil/Desktop/gradnet/trained/rf_model.pkl\", \"rb\") as fh:\n",
    "    rf_model = pickle.load( fh)\n",
    "    \n",
    "with open(\"/home/phil/Desktop/gradnet/trained/gbr_model.pkl\", \"rb\") as fh:\n",
    "    gbr = pickle.load( fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will look at 28 day old samples\n",
    " \n",
    "We saw age was a feature, and is not part of a mixture. This is because concrete takes time to properly cure. As we had many observations for 28 day old samples, we will limit our investigation to these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixture_ingredients = ['Cement','BlastFurnaceSlag','FlyAsh','Water',\n",
    "                       'Superplasticizer','CoarseAggregate','FineAggregate','Age']\n",
    "\n",
    "test_age_28 = test.loc[test.Age == 28, mixture_ingredients]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to optimise\n",
    "\n",
    "The optimiser needs a cost ('objective') function to work with. It will take this function and some starting values, and try to find a minimum.\n",
    "\n",
    "The cost function takes in n-1 of our mixture proportions, and infers the last. We do this to ensure our mixture proportions sum exactly to 1. Once that process is complete, we append the age (28) to our feature vector. This is then fed into our model, and a prediction is generated. The optimiser will explore mixtures from a given starting point to try and find an optimal value, i.e. the mixture proportions which yield the greatest compressive strength.\n",
    "\n",
    "As the optimiser is searching for a minimum, we return the negated compressive strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assume numpy array\n",
    "# x[0] = Cement\n",
    "# x[1] = BlastFurnaceSlag\n",
    "# x[2] = FlyAsh\n",
    "# x[3] = Water\n",
    "# x[4] = Superplasticizer\n",
    "# x[5] = CoarseAggregate\n",
    "\n",
    "def cost_function(x, model):\n",
    "    \n",
    "    # Check to make sure the mixture proportions are in the correct range\n",
    "    # 'explode' the cost function if we violate\n",
    "    if(x[0] < 0.0 or x[1] > 1.0): return(10**38)\n",
    "    if(x[1] < 0.0 or x[1] > 1.0): return(10**38)\n",
    "    if(x[2] < 0.0 or x[2] > 1.0): return(10**38)\n",
    "    if(x[3] < 0.0 or x[3] > 1.0): return(10**38)\n",
    "    if(x[4] < 0.0 or x[4] > 1.0): return(10**38)\n",
    "    if(x[5] < 0.0 or x[5] > 1.0): return(10**38)\n",
    "    \n",
    "    # x[6] = FineAggregate, the proportion is 1 - the rest\n",
    "    x = np.append(x, (1 - np.sum(x)))\n",
    "    \n",
    "    # if unrealistic amount of water\n",
    "    if(x[3] < 0.05): return(10**38)\n",
    "\n",
    "    # add age = 28\n",
    "    x = np.append(x, 28.0)\n",
    "    \n",
    "    # return the prediction from the model\n",
    "    # negate as we want the largest compressive strength, \n",
    "    # and the optimiser will minimise\n",
    "    return -model.predict(x[None, :])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixture optimisation\n",
    "\n",
    "\n",
    "Our strategy is to use  each observation in test set as a starting point (as we know they are realistic mixtures) and try to optimise.\n",
    "\n",
    "Our cost function is not smooth, so we need to be careful which method we use. Nealder-Mead should perform well here.\n",
    "\n",
    "We see not all starting values lead to a solution. We will run an optimisation for each starting value, and return the mixtures which we predict will give the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = np.empty((115, 9))\n",
    "cols = ['Cement','BlastFurnaceSlag','FlyAsh','Water','Superplasticizer','CoarseAggregate']\n",
    "index_vals = test_age_28.index.values\n",
    "\n",
    "for i, ix in enumerate(index_vals):\n",
    "    \n",
    "    # current starting values\n",
    "    curr_values = test_age_28.loc[ix, cols].values\n",
    "    \n",
    "    # perform the optimization\n",
    "    opt = minimize(cost_function, curr_values, args=(gbr), method = \"Nelder-Mead\", options={'maxiter': 5000})\n",
    "    \n",
    "    if i % 25 == 0:\n",
    "        print(\"===============\")\n",
    "        print(\"starting sample\", i)\n",
    "        print(\"compressive strength:\",  -opt.fun)\n",
    "        print(\"mixture:\", opt.x)\n",
    "        print()\n",
    "    \n",
    "    # store our mixtures and prediction of compressive strength\n",
    "    res[i,:6] = opt.x\n",
    "    res[i, 6] = (1.0 - opt.x.sum())\n",
    "    res[i, 7] = 28.0\n",
    "    res[i, 8] = -opt.fun\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets pull out our best predictions\n",
    "(\n",
    "    pd.DataFrame(res, columns = mixture_ingredients + ['CompressiveStrength'])\n",
    "        .sort_values(by = 'CompressiveStrength', ascending = False)\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We have achieved our objective: we have produced a selection of mixes we can propose for further experimentation.\n",
    "\n",
    "To expand this work, we could include other consideration, for instance financial cost. The cost function could be enhanced with desirability function. For instance, if cement is very expensive, the fourth strongest mix prediction would be prohibitave.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python datSci3",
   "language": "python",
   "name": "datsci3-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
